{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EE 123 Lab 2 — Spectral Analysis: Images & Audio\n",
        "\n",
        "### Written by Tingle Li and John Wang, Spring 2026"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this lab we explore spectral analysis in two domains: **images** (2D DFT) and **audio** (1D FFT / STFT). \n",
        "You will visualize frequency content, apply filters in the frequency domain, create hybrid images, \n",
        "analyze real audio spectrograms, and perform tone removal — all using the Fourier transform as the central tool.\n",
        "\n",
        "**Prerequisites:** Lab 1 (DTFT, chirps, cross-correlation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure, figaspect\n",
        "from scipy import signal\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Image Spectral Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.1: 2D DFT Visualization\n",
        "\n",
        "The 2D Discrete Fourier Transform (DFT) decomposes an image into its spatial frequency components. \n",
        "For an $M \\times N$ image $f[m,n]$, the 2D DFT is:\n",
        "\n",
        "$$ F[u,v] = \\sum_{m=0}^{M-1} \\sum_{n=0}^{N-1} f[m,n] \\, e^{-j2\\pi(um/M + vn/N)} $$\n",
        "\n",
        "Low frequencies (near the center after `fftshift`) correspond to smooth regions, \n",
        "while high frequencies (near the edges) correspond to sharp transitions like edges and textures.\n",
        "\n",
        "**Tasks:**\n",
        "* Load three images: the cameraman, a synthetic checkerboard, and a natural scene (astronaut).\n",
        "* Compute the 2D FFT of each. Display the **log-magnitude spectrum** and **phase spectrum** side by side.\n",
        "* Hint: use the `fft2` and `fftshift` functions from `np.fft`. For display, `np.log1p` avoids log(0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage import data as skdata\n",
        "\n",
        "# Load cameraman image\n",
        "cameraman = plt.imread('pictures/cameraman.png')\n",
        "if cameraman.ndim == 3:\n",
        "    cameraman = np.mean(cameraman[:,:,:3], axis=2)\n",
        "if cameraman.max() > 1.0:\n",
        "    cameraman = cameraman / 255.0\n",
        "\n",
        "# Generate a checkerboard pattern (8x8 blocks)\n",
        "block = 32\n",
        "checker = np.kron(\n",
        "    [[1, 0]*4, [0, 1]*4]*4,\n",
        "    np.ones((block, block))\n",
        ")\n",
        "\n",
        "# Natural scene from skimage\n",
        "astronaut_rgb = skdata.astronaut()\n",
        "astronaut = np.mean(astronaut_rgb / 255.0, axis=2)\n",
        "\n",
        "images = {'Cameraman': cameraman, 'Checkerboard': checker, 'Astronaut': astronaut}\n",
        "\n",
        "# Display original images\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "for ax, (name, img) in zip(axes, images.items()):\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.set_title(name)\n",
        "    ax.axis('off')\n",
        "plt.suptitle('Original Images', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute and display 2D FFT: log-magnitude and phase\n",
        "# Hint: for each image, compute the 2D FFT, shift the zero-frequency to center,\n",
        "# then compute log(1 + |F|) for magnitude and the angle for phase.\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(14, 12))\n",
        "\n",
        "for i, (name, img) in enumerate(images.items()):\n",
        "    # TODO: Compute 2D FFT and shift\n",
        "    F_shifted = # TODO\n",
        "    \n",
        "    # TODO: Compute log-magnitude and phase\n",
        "    magnitude = # TODO\n",
        "    phase = # TODO\n",
        "    \n",
        "    # Original\n",
        "    axes[i, 0].imshow(img, cmap='gray')\n",
        "    axes[i, 0].set_title(f'{name} — Original')\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    # Log-magnitude spectrum\n",
        "    axes[i, 1].imshow(magnitude, cmap='gray')\n",
        "    axes[i, 1].set_title(f'{name} — Log-Magnitude Spectrum')\n",
        "    axes[i, 1].axis('off')\n",
        "    \n",
        "    # Phase spectrum\n",
        "    axes[i, 2].imshow(phase, cmap='gray')\n",
        "    axes[i, 2].set_title(f'{name} — Phase Spectrum')\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Compare the spectra of the checkerboard vs. the natural image. \n",
        "Why does the checkerboard have energy concentrated along specific axes, \n",
        "while the natural image does not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.2: Frequency-Domain Filtering\n",
        "\n",
        "Instead of convolving in the spatial domain, we can multiply in the frequency domain (convolution theorem). \n",
        "A **Gaussian low-pass filter** in the frequency domain is:\n",
        "\n",
        "$$ H_{LP}[u,v] = e^{-\\frac{u^2+v^2}{2\\sigma^2}} $$\n",
        "\n",
        "and the corresponding **high-pass filter** is $ H_{HP} = 1 - H_{LP} $.\n",
        "\n",
        "**Tasks:**\n",
        "* Construct a 2D Gaussian low-pass mask in the frequency domain.\n",
        "* Apply low-pass and high-pass filtering to the cameraman image: FFT → multiply by mask → IFFT.\n",
        "* Try **3 different sigma values** (e.g., 10, 30, 80). Display a grid of results.\n",
        "\n",
        "Hint: create a distance matrix $D[u,v] = \\sqrt{u^2 + v^2}$ centered at the image center, \n",
        "then the Gaussian mask is $e^{-D^2/(2\\sigma^2)}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frequency-domain Gaussian filtering\n",
        "img = cameraman\n",
        "rows, cols = img.shape\n",
        "crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "# TODO: Create frequency coordinate grid centered at (crow, ccol)\n",
        "# Hint: use np.arange and np.meshgrid to build U, V arrays\n",
        "# then compute D = distance from center\n",
        "u = # TODO\n",
        "v = # TODO\n",
        "V, U = np.meshgrid(v, u)\n",
        "D = # TODO\n",
        "\n",
        "# Compute FFT of image (shifted)\n",
        "F = np.fft.fftshift(np.fft.fft2(img))\n",
        "\n",
        "sigmas = [10, 30, 80]\n",
        "fig, axes = plt.subplots(len(sigmas), 3, figsize=(14, 12))\n",
        "\n",
        "for i, sigma in enumerate(sigmas):\n",
        "    # TODO: Create Gaussian low-pass and high-pass masks\n",
        "    H_lp = # TODO\n",
        "    H_hp = # TODO\n",
        "    \n",
        "    # TODO: Apply filters in frequency domain and transform back\n",
        "    # Hint: multiply F by mask, then ifftshift + ifft2, take real part\n",
        "    img_lp = # TODO\n",
        "    img_hp = # TODO\n",
        "    \n",
        "    # Display\n",
        "    axes[i, 0].imshow(img, cmap='gray')\n",
        "    axes[i, 0].set_title(f'Original')\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    axes[i, 1].imshow(img_lp, cmap='gray')\n",
        "    axes[i, 1].set_title(f'Low-Pass (σ={sigma})')\n",
        "    axes[i, 1].axis('off')\n",
        "    \n",
        "    axes[i, 2].imshow(img_hp, cmap='gray')\n",
        "    axes[i, 2].set_title(f'High-Pass (σ={sigma})')\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.suptitle('Frequency-Domain Gaussian Filtering', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** You may notice ringing artifacts when using a binary (ideal) circular mask instead \n",
        "of a Gaussian. What causes the ringing, and why does the Gaussian mask reduce it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.3: Hybrid Images\n",
        "\n",
        "A hybrid image combines the low-frequency content of one image with the high-frequency content \n",
        "of another. When viewed up close, the high-frequency image dominates perception; from far away \n",
        "(or when squinting), only the low-frequency image is visible. This directly demonstrates how the \n",
        "human visual system processes spatial frequencies.\n",
        "\n",
        "Here we perform the entire operation in the **Fourier domain** — no spatial convolution needed. \n",
        "This is the convolution theorem in action:\n",
        "\n",
        "$$ \\text{Hybrid} = \\mathcal{F}^{-1}\\left[ F_A \\cdot H_{LP} + F_B \\cdot H_{HP} \\right] $$\n",
        "\n",
        "**Tasks:**\n",
        "* Load the apple and orange images (grayscale).\n",
        "* Low-pass filter image A in the frequency domain: FFT → multiply by Gaussian mask → IFFT.\n",
        "* High-pass filter image B: FFT → multiply by (1 − Gaussian mask) → IFFT.\n",
        "* Add the two results to create the hybrid.\n",
        "* Experiment with 3 different sigma values. Display results and their Fourier transforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load apple and orange (color)\n",
        "apple_rgb = plt.imread('pictures/apple.jpeg')\n",
        "orange_rgb = plt.imread('pictures/orange.jpeg')\n",
        "\n",
        "# Normalize to [0, 1] — keep all 3 color channels\n",
        "apple = apple_rgb / 255.0 if apple_rgb.max() > 1 else apple_rgb.astype(np.float64)\n",
        "orange = orange_rgb / 255.0 if orange_rgb.max() > 1 else orange_rgb.astype(np.float64)\n",
        "\n",
        "# Match sizes\n",
        "H = min(apple.shape[0], orange.shape[0])\n",
        "W = min(apple.shape[1], orange.shape[1])\n",
        "apple = apple[:H, :W]\n",
        "orange = orange[:H, :W]\n",
        "\n",
        "print(f'Image size: {H} x {W} x 3 (RGB)')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "axes[0].imshow(apple); axes[0].set_title('Apple'); axes[0].axis('off')\n",
        "axes[1].imshow(orange); axes[1].set_title('Orange'); axes[1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid image creation in the frequency domain (color — apply per channel)\n",
        "rows, cols = apple.shape[:2]\n",
        "crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "# Reuse the distance matrix approach from Task 1.2\n",
        "u = np.arange(rows) - crow\n",
        "v = np.arange(cols) - ccol\n",
        "V, U = np.meshgrid(v, u)\n",
        "D = np.sqrt(U**2 + V**2)\n",
        "\n",
        "sigmas = [5, 15, 30]\n",
        "\n",
        "fig, axes = plt.subplots(len(sigmas), 4, figsize=(16, 3 * len(sigmas)))\n",
        "\n",
        "for i, sigma in enumerate(sigmas):\n",
        "    # TODO: Create Gaussian low-pass and high-pass masks (same as Task 1.2)\n",
        "    H_lp = # TODO\n",
        "    H_hp = # TODO\n",
        "    \n",
        "    # TODO: Apply filtering per RGB channel\n",
        "    # Hint: loop over channels (range(3)), compute FFT of each channel,\n",
        "    # multiply by the mask, IFFT back, and store in a 3-channel result array\n",
        "    apple_lp = np.zeros_like(apple)\n",
        "    orange_hp = np.zeros_like(orange)\n",
        "    for c in range(3):\n",
        "        F_apple_c = # TODO: FFT of apple[:, :, c], shifted\n",
        "        F_orange_c = # TODO: FFT of orange[:, :, c], shifted\n",
        "        apple_lp[:, :, c] = # TODO: IFFT of filtered apple channel\n",
        "        orange_hp[:, :, c] = # TODO: IFFT of filtered orange channel\n",
        "    \n",
        "    # TODO: Combine and clip\n",
        "    hybrid = # TODO\n",
        "    \n",
        "    # Display\n",
        "    axes[i, 0].imshow(np.clip(apple_lp, 0, 1))\n",
        "    axes[i, 0].set_title(f'Apple LP (σ={sigma})')\n",
        "    axes[i, 0].axis('off')\n",
        "    \n",
        "    axes[i, 1].imshow(np.clip(orange_hp + 0.5, 0, 1))  # shift for visibility\n",
        "    axes[i, 1].set_title(f'Orange HP (σ={sigma})')\n",
        "    axes[i, 1].axis('off')\n",
        "    \n",
        "    axes[i, 2].imshow(hybrid)\n",
        "    axes[i, 2].set_title(f'Hybrid (σ={sigma})')\n",
        "    axes[i, 2].axis('off')\n",
        "    \n",
        "    # Fourier transform of hybrid (show one channel as representative)\n",
        "    F_hybrid = np.fft.fftshift(np.fft.fft2(hybrid[:, :, 1]))\n",
        "    axes[i, 3].imshow(np.log1p(np.abs(F_hybrid)), cmap='gray')\n",
        "    axes[i, 3].set_title(f'Hybrid Spectrum (σ={sigma})')\n",
        "    axes[i, 3].axis('off')\n",
        "\n",
        "plt.suptitle('Hybrid Images at Different Cutoff Frequencies', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's visualize the Fourier transforms at each stage for your best sigma.\n",
        "* **Display the log-magnitude spectrum of:** original apple, filtered apple (LP), \n",
        "  original orange, filtered orange (HP), and the hybrid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed Fourier analysis for your chosen sigma\n",
        "# Use one channel (e.g., green) to show the spectra at each stage\n",
        "# TODO: Pick the sigma that works best from the experiment above\n",
        "sigma = # TODO\n",
        "\n",
        "H_lp = np.exp(-D**2 / (2 * sigma**2))\n",
        "H_hp = 1 - H_lp\n",
        "\n",
        "# TODO: Compute spectra of the green channel (channel index 1) for visualization\n",
        "F_apple_g = # TODO: FFT of apple[:, :, 1], shifted\n",
        "F_apple_lp_g = # TODO: apply low-pass mask\n",
        "F_orange_g = # TODO: FFT of orange[:, :, 1], shifted\n",
        "F_orange_hp_g = # TODO: apply high-pass mask\n",
        "F_hybrid_g = F_apple_lp_g + F_orange_hp_g\n",
        "\n",
        "# Display all spectra\n",
        "spectra = {\n",
        "    'Apple (original)': F_apple_g,\n",
        "    'Apple (low-pass)': F_apple_lp_g,\n",
        "    'Orange (original)': F_orange_g,\n",
        "    'Orange (high-pass)': F_orange_hp_g,\n",
        "    'Hybrid': F_hybrid_g,\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "for ax, (name, spec) in zip(axes, spectra.items()):\n",
        "    ax.imshow(np.log1p(np.abs(spec)), cmap='gray')\n",
        "    ax.set_title(name)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle(f'Log-Magnitude Spectra at Each Stage (σ={sigma})', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** If you squint or shrink the hybrid image to a thumbnail, which image dominates \n",
        "and why? Relate your answer to how the human visual system processes spatial frequencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.4: Phase vs. Magnitude — Which Carries More Information?\n",
        "\n",
        "A Fourier transform $F[u,v]$ is fully described by its **magnitude** $|F[u,v]|$ and **phase** $\\angle F[u,v]$:\n",
        "\n",
        "$$ F[u,v] = |F[u,v]| \\, e^{j\\angle F[u,v]} $$\n",
        "\n",
        "A classic experiment reveals which component matters more for visual perception: take the magnitude spectrum from one image and combine it with the phase spectrum of another, then reconstruct via inverse FFT.\n",
        "\n",
        "**Your task (minimal scaffolding — design the experiment yourself):**\n",
        "* Use two of the grayscale images from Task 1.1 (e.g., `cameraman` and `astronaut`).\n",
        "* Compute the 2D FFT of each image.\n",
        "* Construct two \"swapped\" images:\n",
        "  - **Reconstruction 1:** magnitude of image A + phase of image B\n",
        "  - **Reconstruction 2:** magnitude of image B + phase of image A\n",
        "* Reconstruct via inverse FFT and display all four images (2 originals + 2 reconstructions) in a 2×2 grid.\n",
        "\n",
        "Useful functions: `np.fft.fft2`, `np.fft.ifft2`, `np.abs`, `np.angle`, `np.exp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase vs. Magnitude reconstruction\n",
        "# Images from Task 1.1 are already loaded: cameraman, astronaut\n",
        "# Note: the two images may have different sizes — crop to the smaller dimensions first.\n",
        "\n",
        "# TODO: Crop both images to matching dimensions\n",
        "h = min(cameraman.shape[0], astronaut.shape[0])\n",
        "w = min(cameraman.shape[1], astronaut.shape[1])\n",
        "img_A = cameraman[:h, :w]\n",
        "img_B = astronaut[:h, :w]\n",
        "\n",
        "# TODO: Compute 2D FFT of both images\n",
        "F_A = # TODO\n",
        "F_B = # TODO\n",
        "\n",
        "# TODO: Extract magnitude and phase from each\n",
        "mag_A = # TODO\n",
        "phase_A = # TODO\n",
        "mag_B = # TODO\n",
        "phase_B = # TODO\n",
        "\n",
        "# TODO: Combine — mag(A) + phase(B) and mag(B) + phase(A)\n",
        "# Hint: reconstruct F from magnitude and phase via  mag * exp(1j * phase)\n",
        "recon1 = # TODO\n",
        "recon2 = # TODO\n",
        "\n",
        "# Display\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes[0, 0].imshow(img_A, cmap='gray')\n",
        "axes[0, 0].set_title('Cameraman (original)')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(img_B, cmap='gray')\n",
        "axes[0, 1].set_title('Astronaut (original)')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[1, 0].imshow(recon1, cmap='gray')\n",
        "axes[1, 0].set_title('Mag(Cameraman) + Phase(Astronaut)')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(recon2, cmap='gray')\n",
        "axes[1, 1].set_title('Mag(Astronaut) + Phase(Cameraman)')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "plt.suptitle('Phase vs. Magnitude Reconstruction', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Which image does each reconstruction resemble more — the one that contributed \n",
        "its magnitude, or its phase? What does this tell you about the relative importance of \n",
        "phase vs. magnitude for human visual perception?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1.5: Conceptual Wrap-Up\n",
        "\n",
        "**Question:** In your own words, explain the relationship between spatial features \n",
        "(edges, textures, smooth regions) and their frequency-domain representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Audio Spectral Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.1: FFT of Synthetic Signals\n",
        "\n",
        "We start with synthetic signals where the ground truth is known. Given a signal composed of sinusoids:\n",
        "\n",
        "$$ x[n] = \\sum_{k} A_k \\sin(2\\pi f_k n / f_s) $$\n",
        "\n",
        "the FFT should reveal peaks at exactly $f_1, f_2, \\ldots$ We will also explore two important \n",
        "practical effects: **zero-padding** and **windowing**.\n",
        "\n",
        "**Tasks:**\n",
        "* Generate a signal with 3 sinusoids at 440 Hz, 1000 Hz, and 2500 Hz (sampled at 16 kHz, 0.5 s).\n",
        "* Compute and plot the FFT magnitude spectrum.\n",
        "* Explore zero-padding: compute FFT with N, 2N, 4N points.\n",
        "* Explore windowing: compare rectangular vs. Hann window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic signal: sum of 3 sinusoids\n",
        "fs_audio = 16000\n",
        "T_audio = 0.5  # seconds\n",
        "t_audio = np.arange(0, T_audio, 1.0 / fs_audio)\n",
        "N_audio = len(t_audio)\n",
        "\n",
        "f1, f2, f3 = 440, 1000, 2500\n",
        "\n",
        "# TODO: Generate the signal as a sum of 3 sinusoids\n",
        "# with amplitudes 1.0, 0.7, and 0.5 respectively\n",
        "x = # TODO\n",
        "\n",
        "# TODO: Compute FFT and frequency axis\n",
        "# Hint: use np.fft.fft and np.fft.fftfreq\n",
        "X = # TODO\n",
        "freqs = # TODO\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# Time domain\n",
        "axes[0].plot(t_audio[:500], x[:500])\n",
        "axes[0].set_xlabel('Time [s]')\n",
        "axes[0].set_ylabel('Amplitude')\n",
        "axes[0].set_title('Synthetic Signal (first 500 samples)')\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Frequency domain (positive frequencies only)\n",
        "pos_mask = freqs >= 0\n",
        "axes[1].plot(freqs[pos_mask], np.abs(X[pos_mask]))\n",
        "axes[1].set_xlabel('Frequency [Hz]')\n",
        "axes[1].set_ylabel('|X(f)|')\n",
        "axes[1].set_title('Magnitude Spectrum')\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zero-padding exploration\n",
        "# Hint: pass the n parameter to np.fft.fft to control the FFT length\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "\n",
        "for i, nfft in enumerate([N_audio, 2 * N_audio, 4 * N_audio]):\n",
        "    # TODO: Compute zero-padded FFT\n",
        "    X_zp = # TODO\n",
        "    freqs_zp = # TODO\n",
        "    pos_mask = freqs_zp >= 0\n",
        "    \n",
        "    axes[i].plot(freqs_zp[pos_mask], np.abs(X_zp[pos_mask]))\n",
        "    axes[i].set_xlabel('Frequency [Hz]')\n",
        "    axes[i].set_ylabel('|X(f)|')\n",
        "    axes[i].set_title(f'FFT with {nfft} points ({nfft // N_audio}x zero-padded)')\n",
        "    axes[i].set_xlim([0, 3000])\n",
        "    axes[i].grid(True)\n",
        "\n",
        "plt.suptitle('Effect of Zero-Padding on FFT', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Windowing exploration: rectangular vs. Hann\n",
        "# Hint: np.hanning(N) creates a Hann window of length N.\n",
        "# Multiplying the signal by the window before FFT reduces spectral leakage.\n",
        "\n",
        "# TODO: Create Hann window and apply to signal\n",
        "window_hann = # TODO\n",
        "x_hann = # TODO\n",
        "\n",
        "nfft = 4 * N_audio  # zero-pad for smoother display\n",
        "\n",
        "# TODO: Compute FFTs of rectangular-windowed and Hann-windowed signals\n",
        "X_rect = # TODO\n",
        "X_hann = # TODO\n",
        "freqs_w = np.fft.fftfreq(nfft, 1.0 / fs_audio)\n",
        "pos_mask = freqs_w >= 0\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "# Linear scale\n",
        "axes[0].plot(freqs_w[pos_mask], np.abs(X_rect[pos_mask]), label='Rectangular', alpha=0.7)\n",
        "axes[0].plot(freqs_w[pos_mask], np.abs(X_hann[pos_mask]), label='Hann', alpha=0.7)\n",
        "axes[0].set_xlabel('Frequency [Hz]')\n",
        "axes[0].set_ylabel('|X(f)|')\n",
        "axes[0].set_title('Windowing Effect (Linear Scale)')\n",
        "axes[0].set_xlim([0, 3000])\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# dB scale\n",
        "X_rect_db = 20 * np.log10(np.abs(X_rect[pos_mask]) + 1e-12)\n",
        "X_hann_db = 20 * np.log10(np.abs(X_hann[pos_mask]) + 1e-12)\n",
        "axes[1].plot(freqs_w[pos_mask], X_rect_db, label='Rectangular', alpha=0.7)\n",
        "axes[1].plot(freqs_w[pos_mask], X_hann_db, label='Hann', alpha=0.7)\n",
        "axes[1].set_xlabel('Frequency [Hz]')\n",
        "axes[1].set_ylabel('Magnitude [dB]')\n",
        "axes[1].set_title('Windowing Effect (dB Scale)')\n",
        "axes[1].set_xlim([0, 3000])\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Does zero-padding actually improve frequency resolution, or does it just \n",
        "interpolate the existing spectrum? Explain, and relate back to the DTFT window analysis from Lab 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.2: STFT & Spectrogram — Time-Frequency Tradeoff\n",
        "\n",
        "A single FFT gives us frequency content but loses all time information. The **Short-Time Fourier \n",
        "Transform (STFT)** recovers time localization by applying the FFT to short, overlapping windows:\n",
        "\n",
        "$$ \\text{STFT}\\{x\\}(m, \\omega) = \\sum_{n} x[n] \\, w[n - m] \\, e^{-j\\omega n} $$\n",
        "\n",
        "There is a fundamental tradeoff:\n",
        "* **Short window** → good time resolution, poor frequency resolution\n",
        "* **Long window** → good frequency resolution, poor time resolution\n",
        "\n",
        "**Tasks:**\n",
        "* Generate a synthetic chirp (200 Hz to 4000 Hz, 2 seconds, sampled at 16 kHz).\n",
        "* Compute spectrograms using `librosa.stft` with 3 different `n_fft` values (256, 1024, 4096).\n",
        "* Display and compare. Use `hop_length = n_fft // 4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a synthetic chirp\n",
        "fs_chirp = 16000\n",
        "T_chirp = 2.0\n",
        "t_chirp = np.linspace(0, T_chirp, int(fs_chirp * T_chirp), endpoint=False)\n",
        "\n",
        "f0_chirp = 200\n",
        "f1_chirp = 4000\n",
        "\n",
        "# TODO: Generate the chirp signal\n",
        "# Recall from Lab 1: for a linear chirp, x(t) = sin(2π(f0 + k/2 * t) * t)\n",
        "# where k = (f1 - f0) / T is the chirp rate\n",
        "chirp = # TODO\n",
        "chirp = chirp.astype(np.float32)\n",
        "\n",
        "# Play the chirp\n",
        "ipd.display(ipd.Audio(chirp, rate=fs_chirp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spectrograms with different window sizes\n",
        "n_ffts = [256, 1024, 4096]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, n_fft in enumerate(n_ffts):\n",
        "    hop_length = n_fft // 4\n",
        "    \n",
        "    # TODO: Compute STFT and convert to dB\n",
        "    # Hint: use librosa.stft, then take abs and convert with librosa.amplitude_to_db\n",
        "    S = # TODO\n",
        "    S_db = # TODO\n",
        "    \n",
        "    librosa.display.specshow(S_db, sr=fs_chirp, hop_length=hop_length,\n",
        "                             x_axis='time', y_axis='hz', ax=axes[i])\n",
        "    axes[i].set_title(f'n_fft = {n_fft}\\n'\n",
        "                      f'Time res: {hop_length/fs_chirp*1000:.1f} ms, '\n",
        "                      f'Freq res: {fs_chirp/n_fft:.1f} Hz')\n",
        "    axes[i].set_ylim([0, 5000])\n",
        "\n",
        "plt.suptitle('Time-Frequency Tradeoff: Window Size Effect on Spectrogram', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Why can't you have perfect resolution in both time and frequency simultaneously? \n",
        "Which window size gives the 'best' spectrogram for this chirp, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.3: Real Audio Spectrogram Analysis\n",
        "\n",
        "Now we apply spectrogram analysis to real audio. Musical instruments produce **harmonic** signals: \n",
        "a fundamental frequency $f_0$ plus overtones at integer multiples $2f_0, 3f_0, \\ldots$. \n",
        "We can visualize this structure in the spectrogram.\n",
        "\n",
        "We will also compare the standard (linear-frequency) spectrogram with a **mel-spectrogram**, \n",
        "which uses a perceptually motivated frequency scale that better matches how humans hear pitch.\n",
        "\n",
        "**Tasks:**\n",
        "* Load the `trumpet` and `nutcracker` audio examples from librosa.\n",
        "* Compute and display linear spectrograms and mel-spectrograms side by side.\n",
        "* Use `n_fft=2048`, `hop_length=512`, and `n_mels=128`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load real audio\n",
        "y_trumpet, sr_trumpet = librosa.load(librosa.example('trumpet'))\n",
        "y_nutcracker, sr_nutcracker = librosa.load(librosa.example('nutcracker'))\n",
        "\n",
        "print(f'Trumpet: {len(y_trumpet)/sr_trumpet:.1f}s at {sr_trumpet} Hz')\n",
        "print(f'Nutcracker: {len(y_nutcracker)/sr_nutcracker:.1f}s at {sr_nutcracker} Hz')\n",
        "\n",
        "# Play audio\n",
        "print('\\nTrumpet:')\n",
        "ipd.display(ipd.Audio(y_trumpet, rate=sr_trumpet))\n",
        "print('\\nNutcracker:')\n",
        "ipd.display(ipd.Audio(y_nutcracker, rate=sr_nutcracker))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spectrograms: linear frequency vs mel scale\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# --- Trumpet ---\n",
        "# TODO: Compute linear spectrogram of trumpet\n",
        "# Hint: STFT, then take absolute value, then convert to dB\n",
        "S_trumpet = # TODO\n",
        "S_trumpet_db = # TODO\n",
        "\n",
        "librosa.display.specshow(S_trumpet_db, sr=sr_trumpet, hop_length=512,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Trumpet — Linear Spectrogram')\n",
        "axes[0, 0].set_ylim([0, 8000])\n",
        "\n",
        "# TODO: Compute mel spectrogram of trumpet\n",
        "# Hint: librosa has a function that computes mel spectrograms directly\n",
        "S_trumpet_mel = # TODO\n",
        "S_trumpet_mel_db = # TODO\n",
        "\n",
        "librosa.display.specshow(S_trumpet_mel_db, sr=sr_trumpet, hop_length=512,\n",
        "                         x_axis='time', y_axis='mel', ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Trumpet — Mel Spectrogram')\n",
        "\n",
        "# --- Nutcracker ---\n",
        "# TODO: Repeat for nutcracker (linear and mel)\n",
        "S_nut = # TODO\n",
        "S_nut_db = # TODO\n",
        "\n",
        "librosa.display.specshow(S_nut_db, sr=sr_nutcracker, hop_length=512,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Nutcracker — Linear Spectrogram')\n",
        "axes[1, 0].set_ylim([0, 8000])\n",
        "\n",
        "S_nut_mel = # TODO\n",
        "S_nut_mel_db = # TODO\n",
        "\n",
        "librosa.display.specshow(S_nut_mel_db, sr=sr_nutcracker, hop_length=512,\n",
        "                         x_axis='time', y_axis='mel', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Nutcracker — Mel Spectrogram')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Identify the fundamental frequency and harmonics in the trumpet signal. \n",
        "Why do musical signals show evenly spaced horizontal lines while broadband noise does not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.4: Tone Removal — Filtering in the Frequency Domain\n",
        "\n",
        "Now we put everything together in a practical application. We will:\n",
        "1. Corrupt an audio signal by adding a loud pure tone (1 kHz sine wave).\n",
        "2. Visualize the corruption in the spectrogram.\n",
        "3. Design a **notch filter** in the STFT domain to remove the tone.\n",
        "4. Listen to the before/after — the difference should be dramatic!\n",
        "\n",
        "**Tasks:**\n",
        "* Add a 1 kHz tone at amplitude 0.5 to the trumpet audio.\n",
        "* Compute the STFT, identify the tone visually, and zero out the corresponding frequency bins.\n",
        "* Reconstruct the audio via ISTFT and listen to the result.\n",
        "* Experiment with different notch bandwidths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a loud 1 kHz tone to the trumpet\n",
        "tone_freq = 1000  # Hz\n",
        "tone_amplitude = 0.5\n",
        "\n",
        "# TODO: Generate the 1 kHz tone (same length as y_trumpet)\n",
        "tone = # TODO\n",
        "\n",
        "# TODO: Add tone to trumpet and normalize to prevent clipping\n",
        "y_corrupted = # TODO\n",
        "y_corrupted = y_corrupted / np.max(np.abs(y_corrupted))\n",
        "\n",
        "print('Original trumpet:')\n",
        "ipd.display(ipd.Audio(y_trumpet, rate=sr_trumpet))\n",
        "print('\\nCorrupted (with 1 kHz tone):')\n",
        "ipd.display(ipd.Audio(y_corrupted, rate=sr_trumpet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the corruption in the spectrogram\n",
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "\n",
        "S_orig = librosa.stft(y_trumpet, n_fft=n_fft, hop_length=hop_length)\n",
        "S_corrupt = librosa.stft(y_corrupted, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(S_orig), ref=np.max),\n",
        "                         sr=sr_trumpet, hop_length=hop_length,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[0])\n",
        "axes[0].set_title('Original Trumpet')\n",
        "axes[0].set_ylim([0, 6000])\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(S_corrupt), ref=np.max),\n",
        "                         sr=sr_trumpet, hop_length=hop_length,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[1])\n",
        "axes[1].set_title('Corrupted (1 kHz tone visible as bright horizontal line)')\n",
        "axes[1].set_ylim([0, 6000])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Design and apply a notch filter in the STFT domain\n",
        "# Hint: get the frequency array for the STFT bins, then create a mask\n",
        "# that is 1 everywhere except near the tone frequency.\n",
        "\n",
        "# TODO: Get the frequency values for each STFT bin\n",
        "freqs_stft = # TODO\n",
        "\n",
        "# TODO: Create a notch mask — set bins near tone_freq to 0\n",
        "notch_width = 50  # Hz on each side\n",
        "notch_mask = # TODO\n",
        "\n",
        "# TODO: Apply the mask to the corrupted STFT\n",
        "# Hint: broadcast the 1D mask across all time frames\n",
        "S_filtered = # TODO\n",
        "\n",
        "# TODO: Reconstruct audio from filtered STFT\n",
        "y_filtered = # TODO\n",
        "\n",
        "print('Filtered audio (tone removed):')\n",
        "ipd.display(ipd.Audio(y_filtered, rate=sr_trumpet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare before/after spectrograms\n",
        "S_filt_db = librosa.amplitude_to_db(np.abs(S_filtered), ref=np.max)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(S_orig), ref=np.max),\n",
        "                         sr=sr_trumpet, hop_length=hop_length,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[0])\n",
        "axes[0].set_title('Original (clean)')\n",
        "axes[0].set_ylim([0, 6000])\n",
        "\n",
        "librosa.display.specshow(librosa.amplitude_to_db(np.abs(S_corrupt), ref=np.max),\n",
        "                         sr=sr_trumpet, hop_length=hop_length,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[1])\n",
        "axes[1].set_title('Corrupted (1 kHz tone)')\n",
        "axes[1].set_ylim([0, 6000])\n",
        "\n",
        "librosa.display.specshow(S_filt_db,\n",
        "                         sr=sr_trumpet, hop_length=hop_length,\n",
        "                         x_axis='time', y_axis='hz', ax=axes[2])\n",
        "axes[2].set_title('After Notch Filter')\n",
        "axes[2].set_ylim([0, 6000])\n",
        "\n",
        "plt.suptitle('Tone Removal: Before and After', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment with different notch widths\n",
        "# Try narrow (±10 Hz), medium (±50 Hz), and wide (±200 Hz)\n",
        "notch_widths = [10, 50, 200]\n",
        "\n",
        "fig, axes = plt.subplots(1, len(notch_widths), figsize=(18, 5))\n",
        "\n",
        "for i, nw in enumerate(notch_widths):\n",
        "    # TODO: Create mask, filter, reconstruct, and display\n",
        "    mask = # TODO\n",
        "    \n",
        "    S_filt = S_corrupt * mask[:, np.newaxis]\n",
        "    y_filt = librosa.istft(S_filt, hop_length=hop_length, length=len(y_corrupted))\n",
        "    \n",
        "    S_filt_db = librosa.amplitude_to_db(np.abs(S_filt), ref=np.max)\n",
        "    librosa.display.specshow(S_filt_db, sr=sr_trumpet, hop_length=hop_length,\n",
        "                             x_axis='time', y_axis='hz', ax=axes[i])\n",
        "    axes[i].set_title(f'Notch width = ±{nw} Hz')\n",
        "    axes[i].set_ylim([0, 6000])\n",
        "    \n",
        "    print(f'Notch width ±{nw} Hz:')\n",
        "    ipd.display(ipd.Audio(y_filt, rate=sr_trumpet))\n",
        "\n",
        "plt.suptitle('Effect of Notch Filter Bandwidth', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** What is the tradeoff when choosing the notch filter bandwidth? \n",
        "Describe what you hear when the notch is too narrow vs. too wide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2.5: Pitch Detection via Autocorrelation\n",
        "\n",
        "Periodic signals have a powerful property: their **autocorrelation** peaks at multiples of the fundamental period. The autocorrelation of a discrete signal is:\n",
        "\n",
        "$$ R[k] = \\sum_{n} x[n] \\, x[n+k] $$\n",
        "\n",
        "For a periodic signal with fundamental period $T_0$ samples, $R[k]$ has its first prominent peak (after lag 0) at $k = T_0$. The fundamental frequency is then $f_0 = f_s / T_0$.\n",
        "\n",
        "**Strategy:**\n",
        "1. Extract a short frame (~200 ms) from the trumpet signal.\n",
        "2. Compute the autocorrelation of that frame.\n",
        "3. Find the first peak after a minimum lag (to avoid the trivial peak at lag 0 and implausibly high frequencies).\n",
        "4. Convert the peak lag to a frequency estimate.\n",
        "5. Extend to frame-by-frame pitch tracking and overlay on the spectrogram.\n",
        "\n",
        "This is a real technique used in speech and music analysis — you are building a simplified pitch tracker from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract a single stable frame from the middle of the trumpet for development\n",
        "# y_trumpet and sr_trumpet were loaded in Task 2.3\n",
        "\n",
        "frame_duration = 0.2  # 200 ms — long enough to hear the pitch clearly\n",
        "frame_len = int(sr_trumpet * frame_duration)\n",
        "mid = len(y_trumpet) // 2\n",
        "frame = y_trumpet[mid : mid + frame_len]\n",
        "\n",
        "print(f'Frame: {frame_len} samples ({frame_duration*1000:.0f} ms) at {sr_trumpet} Hz')\n",
        "print(f'Frequency resolution limit: {sr_trumpet / frame_len:.1f} Hz')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 3))\n",
        "t_frame = np.arange(frame_len) / sr_trumpet * 1000\n",
        "ax.plot(t_frame, frame)\n",
        "ax.set_xlabel('Time [ms]')\n",
        "ax.set_ylabel('Amplitude')\n",
        "ax.set_title('Single Trumpet Frame (200 ms from middle of signal)')\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "ipd.display(ipd.Audio(frame, rate=sr_trumpet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Autocorrelation-based pitch detection on a single frame\n",
        "\n",
        "# TODO: Compute the autocorrelation of `frame`\n",
        "# Hint: use np.correlate(frame, frame, mode='full'), then take the right half\n",
        "# (from the center onward) so that lag index 0 = zero lag\n",
        "autocorr = # TODO\n",
        "\n",
        "# TODO: Set a minimum lag to avoid detecting implausibly high frequencies\n",
        "# For example, if max f0 is 1000 Hz, min_lag = sr_trumpet // 1000\n",
        "min_lag = # TODO\n",
        "\n",
        "# TODO: Find the first prominent peak in autocorr[min_lag:]\n",
        "# Hint: you can use scipy.signal.find_peaks or simply np.argmax\n",
        "# on the relevant slice, then add min_lag back to get the true lag\n",
        "peak_lag = # TODO\n",
        "\n",
        "# TODO: Convert lag to frequency\n",
        "f0_estimate = # TODO\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "lags_ms = np.arange(len(autocorr)) / sr_trumpet * 1000\n",
        "ax.plot(lags_ms, autocorr)\n",
        "ax.axvline(peak_lag / sr_trumpet * 1000, color='r', linestyle='--',\n",
        "           label=f'Detected period = {peak_lag} samples → f0 = {f0_estimate:.1f} Hz')\n",
        "ax.set_xlabel('Lag [ms]')\n",
        "ax.set_ylabel('Autocorrelation')\n",
        "ax.set_title('Autocorrelation of Trumpet Frame')\n",
        "ax.legend()\n",
        "ax.set_xlim([0, 30])  # zoom in to relevant range\n",
        "ax.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Estimated fundamental frequency: {f0_estimate:.1f} Hz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frame-by-frame pitch tracking over the full trumpet signal\n",
        "n_fft_pitch = 2048\n",
        "hop_pitch = 512\n",
        "min_lag = sr_trumpet // 1000  # max f0 = 1000 Hz\n",
        "max_lag = sr_trumpet // 50    # min f0 = 50 Hz\n",
        "\n",
        "n_frames = 1 + (len(y_trumpet) - n_fft_pitch) // hop_pitch\n",
        "f0_track = np.zeros(n_frames)\n",
        "\n",
        "for i in range(n_frames):\n",
        "    start = i * hop_pitch\n",
        "    frame_i = y_trumpet[start : start + n_fft_pitch]\n",
        "    \n",
        "    # TODO: Compute autocorrelation of frame_i (same approach as above)\n",
        "    autocorr_i = # TODO\n",
        "    \n",
        "    # TODO: Find first peak in autocorr_i[min_lag:max_lag]\n",
        "    # and convert to frequency. Store in f0_track[i].\n",
        "    # If no clear peak is found (e.g., silence), set f0_track[i] = 0.\n",
        "    f0_track[i] = # TODO\n",
        "\n",
        "# Overlay pitch track on spectrogram\n",
        "S_trumpet_full = librosa.stft(y_trumpet, n_fft=n_fft_pitch, hop_length=hop_pitch)\n",
        "S_trumpet_db = librosa.amplitude_to_db(np.abs(S_trumpet_full), ref=np.max)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 5))\n",
        "librosa.display.specshow(S_trumpet_db, sr=sr_trumpet, hop_length=hop_pitch,\n",
        "                         x_axis='time', y_axis='hz', ax=ax)\n",
        "ax.set_ylim([0, 4000])\n",
        "\n",
        "times = librosa.frames_to_time(np.arange(n_frames), sr=sr_trumpet, hop_length=hop_pitch)\n",
        "valid = f0_track > 0\n",
        "ax.plot(times[valid], f0_track[valid], 'r.', markersize=3, label='Detected f0')\n",
        "ax.legend(loc='upper right')\n",
        "ax.set_title('Pitch Tracking: Autocorrelation f0 Overlaid on Spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question:** Is your pitch estimate consistent across frames? Where does it fail, and why? \n",
        "How could you make the detector more robust (e.g., parabolic interpolation around the peak, \n",
        "thresholding on autocorrelation peak height to reject unvoiced/silent frames)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your answer here:**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
